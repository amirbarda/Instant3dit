model:
  base_learning_rate: 1.0e-5

  target: sgm.models.diffusion.DiffusionEngine
  params:
    scale_factor: 0.13025
    disable_first_stage_autocast: True
    input_key: jpg
    ckpt_path: /home/abarda/mnt/localssd/instant3d/checkpoints/epoch=243-step=10000.ckpt #/home/abarda/mnt/localssd/instant3d/checkpoints/sd_xl_base_1.0.safetensors

    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
      params:
        num_idx: 1000

        weighting_config:
          target: sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting
        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    network_config:
      target: sgm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        adm_in_channels: 2816 #3072
        num_classes: sequential
        use_checkpoint: True
        use_fp16: False # does not seem to make a difference since we can set amp in trainer
        in_channels: 9
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2]
        num_res_blocks: 2
        channel_mult: [1, 2, 4]
        num_head_channels: 64
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: [1, 2, 10]  # note: the first is unused (due to attn_res starting at 2) 32, 16, 8 --> 64, 32, 16
        context_dim: 2048
        spatial_transformer_attn_type: softmax-xformers
        legacy: False

    conditioner_config: #TODO: input mask as conditionig input?
      target: sgm.modules.GeneralConditioner
      params:
        #prob_to_drop_text_embedding: 0.1
        emb_models:
          # crossattn cond
          - is_trainable: False
            input_key: txt
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenCLIPEmbedder
            params:
              layer: hidden
              layer_idx: 11
          # crossattn and vector cond
          - is_trainable: False
            input_key: txt
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder2
            params:
              arch: ViT-bigG-14
              version: laion2b_s39b_b160k
              freeze: True
              layer: penultimate
              always_return_pooled: True
              legacy: False
          # vector cond
          - is_trainable: False
            input_key: original_size_as_tuple
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond
          - is_trainable: False
            input_key: crop_coords_top_left
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond
          - is_trainable: False
            input_key: target_size_as_tuple
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # - is_trainable: False
          #   input_key: mask_type
          #   ucg_rate: 0.1
          #   target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
          #   params:
          #     outdim: 256  # multiplied by two
          
    first_stage_config:
      target: sgm.models.autoencoder.AutoencoderKLInferenceWrapper
      params:
        #ckpt_path: /home/abarda/mnt/localssd/instant3d/checkpoints/epoch=243-step=10000.ckpt #/home/abarda/mnt/localssd/instant3d/checkpoints/sdxl_vae.safetensors
        embed_dim: 4
        # monitor: val/rec_loss
        ddconfig:
          attn_type: vanilla-xformers
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    # scheduler_config:
    #   target: sgm.lr_scheduler.LambdaLinearScheduler
    #   params:
    #     warm_up_steps: [ 10000 ]
    #     cycle_lengths: [ 10000000000000 ]
    #     f_start: [ 1.e-6 ]
    #     f_max: [ 1. ]
    #     f_min: [ 1. ]

    loss_fn_config:
      target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss
      params:
        sigma_sampler_config:
          target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
          params:
            num_idx: 1000

            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    sampler_config:
      target: sgm.modules.diffusionmodules.sampling.BlendedDiffusionSampler
      params:
        num_steps: 100

        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

        guider_config:
          target: sgm.modules.diffusionmodules.guiders.VanillaCFG
          params:
            scale: 5.0

data:
  batch_size: 6
  num_workers: 0
  dataset_config:
    masks_root: mask_data.json
    data_root: training_data
    s3_dirs_filename: render_paths.txt
    captions_filename: captions.csv #Cap3D_automated_Objaverse.csv
    view_type: offset0 # was offset0
    blurring_sigma_range: [3,7]
    excluded_mask_types: []
    #inconsistant_mask_mode: true
    size: 1024
    prompt_suffix: ""
    prompt_prefix: ""
    validation_size: 1

modelcheckpoint:
  save_last: True
  every_n_train_steps: 2000
  save_top_k: -1
  # save_weights_only: True
  save_on_train_epoch_end: False

trainer:
  accelerator: gpu
  precision: 16
  devices: 1
  num_nodes: 1
  strategy: ddp
  # benchmark: True
  num_sanity_val_steps: 1
  accumulate_grad_batches: 1
  log_every_n_steps: 5
  val_check_interval: 200
  # max_epochs: 1
  max_steps: 10